{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1yuMc+W9UiXc/k9rgQZah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diejo57/Quant-Analysis/blob/main/TSLA_daily_returns_1000shares.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datetime import date\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np # Import numpy for calculations\n",
        "\n",
        "print(\"✅ Using pre-installed libraries. No installation needed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D2CzIJVw37w",
        "outputId": "70d65cac-f005-4f0c-de8f-bde85d4b86d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using pre-installed libraries. No installation needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28e5b0f8",
        "outputId": "14c0dd08-7a2a-4176-ed92-fb5c138b4e05"
      },
      "source": [
        "# --- Load the tickers from the provided CSV file ---\n",
        "try:\n",
        "    screener_df = pd.read_csv('/content/nasdaq_screener_1758363072383.csv')\n",
        "    nasdaq_tickers = screener_df['Symbol'].head(1500).tolist()\n",
        "    if 'TSLA' in nasdaq_tickers:\n",
        "        nasdaq_tickers.remove('TSLA')\n",
        "    print(f\"Loaded {len(nasdaq_tickers)} tickers from the CSV file.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: The file 'nasdaq_screener_1758363072383.csv' was not found.\")\n",
        "    nasdaq_tickers = []\n",
        "\n",
        "# --- Define our essential tickers ---\n",
        "additional_tickers = [\n",
        "    'TSLA', '^GSPC', '^IXIC', '^VIX', '^TNX', 'DX-Y.NYB', 'CL=F', 'BTC-USD',\n",
        "]\n",
        "\n",
        "# --- Combine lists and clean symbols ---\n",
        "all_tickers = list(set(nasdaq_tickers + additional_tickers))\n",
        "cleaned_tickers = [ticker.replace('/', '-').replace('.', '-') for ticker in all_tickers]\n",
        "\n",
        "print(f\"Assembled and cleaned a final list of {len(cleaned_tickers)} unique tickers for analysis.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1500 tickers from the CSV file.\n",
            "Assembled and cleaned a final list of 1508 unique tickers for analysis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define the key dates for our test ---\n",
        "prediction_date = date(2025, 9, 19)\n",
        "end_of_training_data = date(2025, 9, 18)\n",
        "start_date = end_of_training_data - pd.DateOffset(years=5)\n",
        "\n",
        "# --- Download and Clean Data ---\n",
        "if cleaned_tickers:\n",
        "    raw_data = yf.download(\n",
        "        tickers=cleaned_tickers,\n",
        "        start=start_date,\n",
        "        end=prediction_date + pd.DateOffset(days=1),\n",
        "        group_by='ticker',\n",
        "        threads=True,\n",
        "        progress=True\n",
        "    )\n",
        "\n",
        "    # --- Robust Data Cleaning ---\n",
        "    data = raw_data.stack(level=0)['Close'].unstack()\n",
        "    data.fillna(method='ffill', inplace=True)\n",
        "    min_valid_obs = int(len(data) * 0.90)\n",
        "    data.dropna(axis=1, thresh=min_valid_obs, inplace=True)\n",
        "    data.dropna(inplace=True)\n",
        "\n",
        "    print(f\"✅ Successfully downloaded and cleaned data for {data.shape[1]} assets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9m1G8VYw4ko",
        "outputId": "e828a882-eaa3-40e2-ef1d-ebb0135aee1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-522556635.py:8: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  raw_data = yf.download(\n",
            "[                       0%                       ]  7 of 1508 completedERROR:yfinance:HTTP Error 404: \n",
            "[*********************100%***********************]  1508 of 1508 completed\n",
            "ERROR:yfinance:\n",
            "97 Failed downloads:\n",
            "ERROR:yfinance:['ASB^F', 'ABR^E', 'BFS^E', 'BC^A', 'AHT^I', 'BC^C', 'ARES^B', 'ALL^H', 'ATCO^H', 'ALB^A', 'CDR^B', 'CIM^A', 'AHT^F', 'BCV^A', 'AHT^G', 'AHL^D', 'BAC^P', 'ANG^D', 'AGM^G', 'CFG^E', 'CMS^C', 'AMH^H', 'BA^A', 'C^N', 'BML^J', 'BAC^O', 'BHR^B', 'AGM^E', 'AHT^D', 'BML^G', 'CIM^D', 'ADC^A', 'ALTG^A', 'ABR^F', 'BAC^M', 'BOH^B', 'AMH^G', 'ACR^C', 'BML^L', 'AHH^A', 'BAC^B', 'CHMI^A', 'ALL^B', 'CDR^C', 'BIP^B', 'CMS^B', 'BANC^F', 'AGM^H', 'ANG^B', 'ACR^D', 'ABR^D', 'BK^K', 'BOH^A', 'BHR^D', 'AUB^A', 'AXS^E', 'BFS^D', 'CFR^B', 'CHMI^B', 'CFG^H', 'CADE^A', 'AHL^F', 'ALL^J', 'ATH^B', 'CMA^B', 'CNO^A', 'CIM^B', 'CIO^A', 'ALL^I', 'DX-Y-NYB', 'BW^A', 'BAC^S', 'ATH^E', 'ATH^A', 'BML^H', 'BAC^N', 'ATH^D', 'BAC^K', 'CMRE^D', 'CMRE^B', 'BAC^Q', 'AGM^D', 'CIM^C', 'BEP^A', 'APO^A', 'AHT^H', 'BAC^E', 'ACP^A', 'AGM^F', 'CLDT^A', 'CFG^I', 'CMRE^C', 'BIP^A', 'BAC^L', 'ARR^C', 'ASB^E', 'AHL^E']: YFTzMissingError('possibly delisted; no timezone found')\n",
            "/tmp/ipython-input-522556635.py:18: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
            "  data = raw_data.stack(level=0)['Close'].unstack()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully downloaded and cleaned data for 979 assets.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-522556635.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data.fillna(method='ffill', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Create a DataFrame to hold the indicators ---\n",
        "indicators = pd.DataFrame(index=data.index)\n",
        "\n",
        "# --- 1. Simple Moving Average (SMA) ---\n",
        "indicators['TSLA_SMA50'] = data['TSLA'].rolling(window=50).mean()\n",
        "\n",
        "# --- 2. Bollinger Bands ---\n",
        "window = 20\n",
        "sma_20 = data['TSLA'].rolling(window=window).mean()\n",
        "std_dev = data['TSLA'].rolling(window=window).std()\n",
        "indicators['TSLA_BB_UPPER'] = sma_20 + (std_dev * 2)\n",
        "indicators['TSLA_BB_LOWER'] = sma_20 - (std_dev * 2)\n",
        "\n",
        "# --- 3. Relative Strength Index (RSI) ---\n",
        "delta = data['TSLA'].diff()\n",
        "gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "rs = gain / loss\n",
        "indicators['TSLA_RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "print(\"✅ Technical indicators calculated manually.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmBnY9b0z4qg",
        "outputId": "d79b8f0f-6028-4e6a-be1c-15c2248b2770"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Technical indicators calculated manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Calculate daily returns ---\n",
        "returns = data.pct_change()\n",
        "\n",
        "# --- Create Lagged Features ---\n",
        "features = returns.copy().shift(1)\n",
        "lagged_indicators = indicators.shift(1)\n",
        "\n",
        "# --- Create the Regression Target Variable ---\n",
        "target = returns['TSLA'].rename('Target_Return')\n",
        "\n",
        "# --- Combine all features into a final DataFrame ---\n",
        "final_df = features.join(target, how='inner')\n",
        "final_df = final_df.join(lagged_indicators, how='inner')\n",
        "\n",
        "# --- NEW: Clean non-finite values (NaN, inf, -inf) that can cause errors ---\n",
        "final_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "final_df.dropna(inplace=True)\n",
        "\n",
        "print(\"✅ Final DataFrame created and cleaned.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5D4y-1K1_lI",
        "outputId": "fa2e550b-58c6-419c-d2d1-86e188599b5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final DataFrame created and cleaned.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ensure the index is a DatetimeIndex before proceeding ---\n",
        "final_df.index = pd.to_datetime(final_df.index)\n",
        "\n",
        "# --- A more robust way to isolate the data by position ---\n",
        "# The last row contains our known outcome (for Sep 19th)\n",
        "last_day_data = final_df.iloc[-1]\n",
        "# The second-to-last row contains the features we use for prediction (from Sep 18th)\n",
        "prediction_input_day = final_df.iloc[-2]\n",
        "\n",
        "# --- Isolate the data for our single-day backtest ---\n",
        "X_predict = prediction_input_day.drop('Target_Return').to_frame().T\n",
        "actual_result = last_day_data['Target_Return']\n",
        "\n",
        "# --- Correctly define the training data (everything EXCEPT the last two days) ---\n",
        "training_data = final_df.iloc[:-2]\n",
        "X_train = training_data.drop(columns='Target_Return')\n",
        "y_train = training_data['Target_Return']\n",
        "\n",
        "# --- Train the scikit-learn regression model ---\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    min_samples_split=10,\n",
        "    random_state=42,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(f\"--- Starting Model Training on data up to {training_data.index[-1].date()} ---\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"--- Model Training Complete ---\")\n",
        "\n",
        "# --- Make the prediction ---\n",
        "predicted_result = model.predict(X_predict)[0]\n",
        "\n",
        "# --- Display Final Result ---\n",
        "print(\"\\n=========================================================\")\n",
        "print(f\"  Return Prediction Backtest (for {last_day_data.name.date()})  \")\n",
        "print(\"=========================================================\")\n",
        "print(f\"Predicted Return: {predicted_result * 100: .4f}%\")\n",
        "print(f\"Actual Return:    {actual_result * 100: .4f}%\")\n",
        "print(\"=========================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iteZ-G92EBz",
        "outputId": "f3ebf9ee-df37-485d-f8d3-75befc3e6158"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Model Training on data up to 2025-09-17 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model Training Complete ---\n",
            "\n",
            "=========================================================\n",
            "  Return Prediction Backtest (for 2025-09-19)  \n",
            "=========================================================\n",
            "Predicted Return:  1.3174%\n",
            "Actual Return:     2.2118%\n",
            "=========================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  4.3min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        }
      ]
    }
  ]
}